# ViT

## Usage:
python train.py

## Parameters:
change parameters.json for self-defined structures
## Possible next steps:
Change model structures for potential performance boosts\
Hyperparameter search for fine tunning\
Data selections and preprocessing (currently from https://www.cs.toronto.edu/~kriz/cifar.html dataset)
## Resources
- Vision Transformer from Scratch https://github.com/tintn/vision-transformer-from-scratch
- Implementing Vision Transformer (ViT) from Scratch https://towardsdatascience.com/implementing-vision-transformer-vit-from-scratch-3e192c6155f0
- MAE git repo, with pretrained checkpoints https://github.com/facebookresearch/mae
- Transformer Easy Start: https://transformers.run/
- Vision Mamba: https://github.com/hustvl/Vim?tab=readme-ov-file
- https://wandb.ai/amogkam/transformers/reports/Hyperparameter-Optimization-for-HuggingFace-Transformers--VmlldzoyMTc2ODI
